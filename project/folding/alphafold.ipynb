{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4yBrceuFbf3"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/sokrypton/ColabFold/main/.github/ColabFold_Marv_Logo_Small.png\" height=\"200\" align=\"right\" style=\"height:240px\">\n",
        "\n",
        "## ColabFold v1.5.5: AlphaFold2 using MMseqs2\n",
        "\n",
        "Easy to use protein structure and complex prediction using [AlphaFold2](https://www.nature.com/articles/s41586-021-03819-2) and [Alphafold2-multimer](https://www.biorxiv.org/content/10.1101/2021.10.04.463034v1). Sequence alignments/templates are generated through [MMseqs2](mmseqs.com) and [HHsearch](https://github.com/soedinglab/hh-suite). For more details, see <a href=\"#Instructions\">bottom</a> of the notebook, checkout the [ColabFold GitHub](https://github.com/sokrypton/ColabFold) and read our manuscript.\n",
        "Old versions: [v1.4](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.4.0/AlphaFold2.ipynb), [v1.5.1](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.5.1/AlphaFold2.ipynb), [v1.5.2](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.5.2/AlphaFold2.ipynb), [v1.5.3-patch](https://colab.research.google.com/github/sokrypton/ColabFold/blob/56c72044c7d51a311ca99b953a71e552fdc042e1/AlphaFold2.ipynb)\n",
        "\n",
        "[Mirdita M, SchÃ¼tze K, Moriwaki Y, Heo L, Ovchinnikov S, Steinegger M. ColabFold: Making protein folding accessible to all.\n",
        "*Nature Methods*, 2022](https://www.nature.com/articles/s41592-022-01488-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "index_offset = 25\n",
        "\n",
        "with Path('target_sequences.json').open() as file:\n",
        "  target_sequences = json.load(file)[index_offset:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOblAo-xetgx",
        "outputId": "7876bfce-f2d4-468b-9cc3-40a5871756d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "jobname test_a5e17\n",
            "sequence PIAQIHILEGRSDEQKETLIREVSEAISRSLDAPLTSVRVIITEMAKGHFGIGGELASK\n",
            "length 59\n"
          ]
        }
      ],
      "source": [
        "#@title Input protein sequence(s), then hit `Runtime` -> `Run all`\n",
        "from google.colab import files\n",
        "import os\n",
        "import re\n",
        "import hashlib\n",
        "import random\n",
        "\n",
        "from sys import version_info\n",
        "python_version = f\"{version_info.major}.{version_info.minor}\"\n",
        "\n",
        "def add_hash(x,y):\n",
        "  return x+\"_\"+hashlib.sha1(y.encode()).hexdigest()[:5]\n",
        "\n",
        "# query_sequence = 'PIAQIHILEGRSDEQKETLIREVSEAISRSLDAPLTSVRVIITEMAKGHFGIGGELASK' #@param {type:\"string\"}\n",
        "#@markdown  - Use `:` to specify inter-protein chainbreaks for **modeling complexes** (supports homo- and hetro-oligomers). For example **PI...SK:PI...SK** for a homodimer\n",
        "# jobname = 'test' #@param {type:\"string\"}\n",
        "# number of models to use\n",
        "num_relax = 0 #@param [0, 1, 5] {type:\"raw\"}\n",
        "#@markdown - specify how many of the top ranked structures to relax using amber\n",
        "template_mode = \"none\" #@param [\"none\", \"pdb100\",\"custom\"]\n",
        "#@markdown - `none` = no template information is used. `pdb100` = detect templates in pdb100 (see [notes](#pdb100)). `custom` - upload and search own templates (PDB or mmCIF format, see [notes](#custom_templates))\n",
        "\n",
        "use_amber = num_relax > 0\n",
        "\n",
        "# # remove whitespaces\n",
        "# query_sequence = \"\".join(query_sequence.split())\n",
        "\n",
        "# basejobname = \"\".join(jobname.split())\n",
        "# basejobname = re.sub(r'\\W+', '', basejobname)\n",
        "# jobname = add_hash(basejobname, query_sequence)\n",
        "\n",
        "# # check if directory with jobname exists\n",
        "# def check(folder):\n",
        "#   if os.path.exists(folder):\n",
        "#     return False\n",
        "#   else:\n",
        "#     return True\n",
        "# if not check(jobname):\n",
        "#   n = 0\n",
        "#   while not check(f\"{jobname}_{n}\"): n += 1\n",
        "#   jobname = f\"{jobname}_{n}\"\n",
        "\n",
        "# # make directory to save results\n",
        "# os.makedirs(jobname, exist_ok=True)\n",
        "\n",
        "# # save queries\n",
        "# queries_path = os.path.join(jobname, f\"{jobname}.csv\")\n",
        "# with open(queries_path, \"w\") as text_file:\n",
        "#   text_file.write(f\"id,sequence\\n{jobname},{query_sequence}\")\n",
        "\n",
        "if template_mode == \"pdb100\":\n",
        "  use_templates = True\n",
        "  custom_template_path = None\n",
        "# elif template_mode == \"custom\":\n",
        "#   custom_template_path = os.path.join(jobname,f\"template\")\n",
        "#   os.makedirs(custom_template_path, exist_ok=True)\n",
        "#   uploaded = files.upload()\n",
        "#   use_templates = True\n",
        "#   for fn in uploaded.keys():\n",
        "#     os.rename(fn,os.path.join(custom_template_path,fn))\n",
        "else:\n",
        "  custom_template_path = None\n",
        "  use_templates = False\n",
        "\n",
        "# print(\"jobname\",jobname)\n",
        "# print(\"sequence\",query_sequence)\n",
        "# print(\"length\",len(query_sequence.replace(\":\",\"\")))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzIKiDiCaHAn",
        "outputId": "44bb2869-bd2b-4bb2-9954-0438f2d04c61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "installing colabfold...\n",
            "CPU times: user 143 ms, sys: 11.2 ms, total: 154 ms\n",
            "Wall time: 40.4 s\n"
          ]
        }
      ],
      "source": [
        "#@title Install dependencies\n",
        "%%time\n",
        "import os\n",
        "USE_AMBER = use_amber\n",
        "USE_TEMPLATES = use_templates\n",
        "PYTHON_VERSION = python_version\n",
        "\n",
        "if not os.path.isfile(\"COLABFOLD_READY\"):\n",
        "  print(\"installing colabfold...\")\n",
        "  os.system(\"pip install -q --no-warn-conflicts 'colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold'\")\n",
        "  if os.environ.get('TPU_NAME', False) != False:\n",
        "    os.system(\"pip install -q --no-warn-conflicts -U dm-haiku==0.0.10 jax==0.3.25\")\n",
        "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/colabfold colabfold\")\n",
        "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/alphafold alphafold\")\n",
        "  os.system(\"touch COLABFOLD_READY\")\n",
        "\n",
        "if USE_AMBER or USE_TEMPLATES:\n",
        "  if not os.path.isfile(\"CONDA_READY\"):\n",
        "    print(\"installing conda...\")\n",
        "    os.system(\"wget -qnc https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-Linux-x86_64.sh\")\n",
        "    os.system(\"bash Mambaforge-Linux-x86_64.sh -bfp /usr/local\")\n",
        "    os.system(\"mamba config --set auto_update_conda false\")\n",
        "    os.system(\"touch CONDA_READY\")\n",
        "\n",
        "if USE_TEMPLATES and not os.path.isfile(\"HH_READY\") and USE_AMBER and not os.path.isfile(\"AMBER_READY\"):\n",
        "  print(\"installing hhsuite and amber...\")\n",
        "  os.system(f\"mamba install -y -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 openmm=7.7.0 python='{PYTHON_VERSION}' pdbfixer\")\n",
        "  os.system(\"touch HH_READY\")\n",
        "  os.system(\"touch AMBER_READY\")\n",
        "else:\n",
        "  if USE_TEMPLATES and not os.path.isfile(\"HH_READY\"):\n",
        "    print(\"installing hhsuite...\")\n",
        "    os.system(f\"mamba install -y -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 python='{PYTHON_VERSION}'\")\n",
        "    os.system(\"touch HH_READY\")\n",
        "  if USE_AMBER and not os.path.isfile(\"AMBER_READY\"):\n",
        "    print(\"installing amber...\")\n",
        "    os.system(f\"mamba install -y -c conda-forge openmm=7.7.0 python='{PYTHON_VERSION}' pdbfixer\")\n",
        "    os.system(\"touch AMBER_READY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@markdown ### MSA options (custom MSA upload, single sequence, pairing mode)\n",
        "msa_mode = \"mmseqs2_uniref_env\" #@param [\"mmseqs2_uniref_env\", \"mmseqs2_uniref\",\"single_sequence\",\"custom\"]\n",
        "pair_mode = \"unpaired_paired\" #@param [\"unpaired_paired\",\"paired\",\"unpaired\"] {type:\"string\"}\n",
        "#@markdown - \"unpaired_paired\" = pair sequences from same species + unpaired MSA, \"unpaired\" = seperate MSA for each chain, \"paired\" - only use paired sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "ADDuaolKmjGW"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Advanced settings\n",
        "model_type = \"auto\" #@param [\"auto\", \"alphafold2_ptm\", \"alphafold2_multimer_v1\", \"alphafold2_multimer_v2\", \"alphafold2_multimer_v3\", \"deepfold_v1\"]\n",
        "#@markdown - if `auto` selected, will use `alphafold2_ptm` for monomer prediction and `alphafold2_multimer_v3` for complex prediction.\n",
        "#@markdown Any of the mode_types can be used (regardless if input is monomer or complex).\n",
        "num_recycles = \"3\" #@param [\"auto\", \"0\", \"1\", \"3\", \"6\", \"12\", \"24\", \"48\"]\n",
        "#@markdown - if `auto` selected, will use `num_recycles=20` if `model_type=alphafold2_multimer_v3`, else `num_recycles=3` .\n",
        "recycle_early_stop_tolerance = \"auto\" #@param [\"auto\", \"0.0\", \"0.5\", \"1.0\"]\n",
        "#@markdown - if `auto` selected, will use `tol=0.5` if `model_type=alphafold2_multimer_v3` else `tol=0.0`.\n",
        "relax_max_iterations = 200 #@param [0, 200, 2000] {type:\"raw\"}\n",
        "#@markdown - max amber relax iterations, `0` = unlimited (AlphaFold2 default, can take very long)\n",
        "pairing_strategy = \"greedy\" #@param [\"greedy\", \"complete\"] {type:\"string\"}\n",
        "#@markdown - `greedy` = pair any taxonomically matching subsets, `complete` = all sequences have to match in one line.\n",
        "\n",
        "\n",
        "#@markdown #### Sample settings\n",
        "#@markdown -  enable dropouts and increase number of seeds to sample predictions from uncertainty of the model.\n",
        "#@markdown -  decrease `max_msa` to increase uncertainity\n",
        "max_msa = \"auto\" #@param [\"auto\", \"512:1024\", \"256:512\", \"64:128\", \"32:64\", \"16:32\"]\n",
        "num_seeds = 1 #@param [1,2,4,8,16] {type:\"raw\"}\n",
        "use_dropout = False #@param {type:\"boolean\"}\n",
        "\n",
        "num_recycles = None if num_recycles == \"auto\" else int(num_recycles)\n",
        "recycle_early_stop_tolerance = None if recycle_early_stop_tolerance == \"auto\" else float(recycle_early_stop_tolerance)\n",
        "if max_msa == \"auto\": max_msa = None\n",
        "\n",
        "#@markdown #### Save settings\n",
        "save_all = False #@param {type:\"boolean\"}\n",
        "save_recycles = False #@param {type:\"boolean\"}\n",
        "save_to_google_drive = False #@param {type:\"boolean\"}\n",
        "#@markdown -  if the save_to_google_drive option was selected, the result zip will be uploaded to your Google Drive\n",
        "dpi = 200 #@param {type:\"integer\"}\n",
        "#@markdown - set dpi for image resolution\n",
        "\n",
        "# if save_to_google_drive:\n",
        "#   from pydrive2.drive import GoogleDrive\n",
        "#   from pydrive2.auth import GoogleAuth\n",
        "#   from google.colab import auth\n",
        "#   from oauth2client.client import GoogleCredentials\n",
        "#   auth.authenticate_user()\n",
        "#   gauth = GoogleAuth()\n",
        "#   gauth.credentials = GoogleCredentials.get_application_default()\n",
        "#   drive = GoogleDrive(gauth)\n",
        "#   print(\"You are logged into Google Drive and are good to go!\")\n",
        "\n",
        "#@markdown Don't forget to hit `Runtime` -> `Run all` after updating the form."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "C2_sh2uAonJH"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "from Bio import BiopythonDeprecationWarning\n",
        "warnings.simplefilter(action='ignore', category=BiopythonDeprecationWarning)\n",
        "from colabfold.download import download_alphafold_params, default_data_dir\n",
        "from colabfold.utils import setup_logging\n",
        "from colabfold.batch import get_queries, run, set_model_type\n",
        "from colabfold.plot import plot_msa_v2\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "try:\n",
        "  K80_chk = os.popen('nvidia-smi | grep \"Tesla K80\" | wc -l').read()\n",
        "except:\n",
        "  K80_chk = \"0\"\n",
        "  pass\n",
        "if \"1\" in K80_chk:\n",
        "  print(\"WARNING: found GPU Tesla K80: limited to total length < 1000\")\n",
        "  if \"TF_FORCE_UNIFIED_MEMORY\" in os.environ:\n",
        "    del os.environ[\"TF_FORCE_UNIFIED_MEMORY\"]\n",
        "  if \"XLA_PYTHON_CLIENT_MEM_FRACTION\" in os.environ:\n",
        "    del os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]\n",
        "\n",
        "# For some reason we need that to get pdbfixer to import\n",
        "if use_amber and f\"/usr/local/lib/python{python_version}/site-packages/\" not in sys.path:\n",
        "    sys.path.insert(0, f\"/usr/local/lib/python{python_version}/site-packages/\")\n",
        "\n",
        "\n",
        "output_path = Path('output')\n",
        "output_path.mkdir(exist_ok=True)\n",
        "\n",
        "for target_index, target_sequence in tqdm(list(enumerate(target_sequences))):\n",
        "  target_path = output_path / f'{(index_offset + target_index):04}'\n",
        "  target_path.mkdir(exist_ok=True)\n",
        "  # query_path = target_path / 'query.csv'\n",
        "\n",
        "  # with query_path.open('w') as file:\n",
        "  #   file.write(f'id,sequence\\nmain,{target_sequence}')\n",
        "\n",
        "  def input_features_callback(input_features):\n",
        "    pass\n",
        "\n",
        "  def prediction_callback(protein_obj, length, prediction_result, input_features, mode):\n",
        "    pass\n",
        "\n",
        "  setup_logging(target_path / 'log.txt')\n",
        "\n",
        "  # queries, is_complex = get_queries(query_path)\n",
        "  # print(queries)\n",
        "  # print(is_complex)\n",
        "\n",
        "  queries = [('main', target_sequence, None)]\n",
        "  is_complex = False\n",
        "\n",
        "  model_type = set_model_type(is_complex, model_type)\n",
        "\n",
        "  use_cluster_profile = not ('multimer' in model_type and max_msa is not None)\n",
        "\n",
        "  download_alphafold_params(model_type, Path(\".\"))\n",
        "  results = run(\n",
        "      queries=queries,\n",
        "      result_dir=str(target_path),\n",
        "      use_templates=use_templates,\n",
        "      custom_template_path=custom_template_path,\n",
        "      num_relax=num_relax,\n",
        "      msa_mode=msa_mode,\n",
        "      model_type=model_type,\n",
        "      num_models=1,\n",
        "      num_recycles=num_recycles,\n",
        "      relax_max_iterations=relax_max_iterations,\n",
        "      recycle_early_stop_tolerance=recycle_early_stop_tolerance,\n",
        "      num_seeds=num_seeds,\n",
        "      use_dropout=use_dropout,\n",
        "      model_order=[1],\n",
        "      is_complex=is_complex,\n",
        "      data_dir=Path(\".\"),\n",
        "      keep_existing_results=False,\n",
        "      rank_by=\"auto\",\n",
        "      pair_mode=pair_mode,\n",
        "      pairing_strategy=pairing_strategy,\n",
        "      stop_at_score=100.0,\n",
        "      prediction_callback=prediction_callback,\n",
        "      dpi=dpi,\n",
        "      zip_results=False,\n",
        "      save_all=save_all,\n",
        "      max_msa=max_msa,\n",
        "      use_cluster_profile=use_cluster_profile,\n",
        "      input_features_callback=input_features_callback,\n",
        "      save_recycles=save_recycles,\n",
        "      user_agent='colabfold/google-colab-main',\n",
        "  )\n",
        "\n",
        "  # results_zip = f\"{jobname}.result.zip\"\n",
        "  # os.system(f\"zip -r {results_zip} {jobname}\")\n",
        "\n",
        "  # decide which a3m to use\n",
        "  # if \"mmseqs2\" in msa_mode:\n",
        "  #   a3m_file = os.path.join(jobname,f\"{jobname}.a3m\")\n",
        "\n",
        "  # elif msa_mode == \"custom\":\n",
        "  #   a3m_file = os.path.join(jobname,f\"{jobname}.custom.a3m\")\n",
        "  #   if not os.path.isfile(a3m_file):\n",
        "  #     custom_msa_dict = files.upload()\n",
        "  #     custom_msa = list(custom_msa_dict.keys())[0]\n",
        "  #     header = 0\n",
        "  #     import fileinput\n",
        "  #     for line in fileinput.FileInput(custom_msa,inplace=1):\n",
        "  #       if line.startswith(\">\"):\n",
        "  #         header = header + 1\n",
        "  #       if not line.rstrip():\n",
        "  #         continue\n",
        "  #       if line.startswith(\">\") == False and header == 1:\n",
        "  #         query_sequence = line.rstrip()\n",
        "  #       print(line, end='')\n",
        "\n",
        "  #     os.rename(custom_msa, a3m_file)\n",
        "  #     queries_path=a3m_file\n",
        "  #     print(f\"moving {custom_msa} to {a3m_file}\")\n",
        "\n",
        "  # else:\n",
        "  #   a3m_file = os.path.join(jobname,f\"{jobname}.single_sequence.a3m\")\n",
        "  #   with open(a3m_file, \"w\") as text_file:\n",
        "  #     text_file.write(\">1\\n%s\" % query_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "33g5IIegij5R",
        "outputId": "39c89f99-74a0-46fb-d871-9e2a35b8a53f"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_6b255be6-64f6-40f8-8d2b-d93e7e2c8c4b\", \"test_a5e17.result.zip\", 1371595)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Package and download results\n",
        "\n",
        "os.system(f\"zip -r output.zip {str(output_path)}\")\n",
        "files.download(\"output.zip\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "name": "AlphaFold2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
