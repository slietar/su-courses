{"cells":[{"cell_type":"markdown","metadata":{"id":"jZ4D84xglI83"},"source":["Nous allons entraîner un classifieur pour distinguer deux familles de protéines : \tABC transporter (PF00005) et \tSH2 domain (PF00017).\n"]},{"cell_type":"markdown","metadata":{"id":"4IQtP0WFl55E"},"source":["1. Charger le fichier trainSeed.csv dans un data frame, la\n","première colonne contient les séquences et la deuxième leur classe PF00017 et PF00005.\n","Puis séparer les séquences et les classes en créant deux objets\n","`Xseqs` et `Y`. Xseqs contient les séquences en acid amine, `Y` l'identifiant Pfam. Dans `Y` nous pouvons remplacer PF00017 par 0 et PF00005 par 1."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"PueUL6RSmvsw"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"5z1kkab0pJZ1"},"outputs":[],"source":["df = pd.read_csv('trainSeed.csv')\n","# print(df)\n","\n","Xseqs = df['Sequence'].values\n","Y = (df['family'].values == 'PF00005').astype(int)\n"]},{"cell_type":"markdown","metadata":{"id":"SiGUJzOSm3We"},"source":["2. Nous allons utiliser la bibliothèque [protlearn](https://protlearn.readthedocs.io/en/latest/feature_extraction.html) pour extraire des features qui décrivent nos séquences protéiques. Utiliser la méthode ngram (n=2) pour extraire les fréquences de répétition de dinucléotides pour chaque sequence de `Xseqs`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z3l2f5IroLpP"},"outputs":[],"source":["!pip install protlearn\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"ESRPZ35n195l"},"outputs":[],"source":["from protlearn.features import ngram\n","\n","X, _ = ngram(list(Xseqs), n=2)\n"]},{"cell_type":"markdown","metadata":{"id":"sXAhR1acSIhA"},"source":["3. Pour entraîner un modèle ML avec [sklearn](https://scikit-learn.org/stable/index.html) nous avons besoin de deux objets ndArray: `X` (de dimensions (NxM) qui comporte les `M` features de chaque protéine) et `y` (de dimension (Nx1) qui contient leurs classes), où N est le nombre total de samples (protéines) dans le dataset. Créer ces deux objets à partir des données chargées précédemment."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"mf4ICX_LsYeN"},"outputs":[{"name":"stdout","output_type":"stream","text":["X.shape=(95, 400) Y.shape=(95,)\n"]}],"source":["# X.shape = (95, 400); y.shape = (95,)\n","\n","print(f'{X.shape=} {Y.shape=}')\n"]},{"cell_type":"markdown","metadata":{"id":"ZBMdhXd8suHN"},"source":["4. Créer un modèle ML du type KNN (k=3), et juste pour avoir un aperçu de sa performance calculer son score sur les données d'entrainement X."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"Ocd0tKXel3tB"},"outputs":[{"data":{"text/plain":["0.8210526315789474"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","c = KNeighborsClassifier(n_neighbors=3)\n","c.fit(X, Y)\n","c.score(X, Y)\n","\n","#score sur tout = 0.8210526315789474\n"]},{"cell_type":"markdown","metadata":{"id":"1VgvHosGtLco"},"source":["5. Diviser les données en deux parties, une pour l'entraînement et une pour le test. Utiliser `random_state=5` et `test_size=0.2`.\n","Entraîner le modèle K-NN (k= 3) sur les données d'entraînement et mesurer sa performance sur les données de test. Comparer les scores obtenu sur les donneées de test et sur le données de training.\n"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"5wWuXKHMtTBu"},"outputs":[{"data":{"text/plain":["(0.7894736842105263, 0.42105263157894735)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.model_selection import train_test_split\n","\n","trainX, testX, trainY, testY = train_test_split(X, Y, random_state=5, test_size=0.2)\n","\n","c = KNeighborsClassifier(n_neighbors=3)\n","c.fit(trainX, trainY)\n","c.score(trainX, trainY), c.score(testX, testY)\n","\n","#score sur training = 0.7894736842105263\n","#score sur test = 0.42105263157894735\n"]},{"cell_type":"markdown","metadata":{"id":"kinDgT-awkau"},"source":["6. Une étape importante avant d'entraîner les modèles ML, est la normalisation des données. Normaliser les données en utilisant la méthode minmax puis recalculer le score sur les données de test ? Discutez vos résultats.\n"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"fQiyELcXxX6e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Score on normalized test data: 0.47368421052631576\n"]}],"source":["from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","trainX_scaled = scaler.fit_transform(trainX)\n","testX_scaled = scaler.transform(testX)\n","\n","c = KNeighborsClassifier(n_neighbors=3)\n","c.fit(trainX_scaled, trainY)\n","score_normalized = c.score(testX_scaled, testY)\n","print(f\"Score on normalized test data: {score_normalized}\")\n","\n","#score sur test normalisé = 0.47368421052631576\n"]},{"cell_type":"markdown","metadata":{"id":"MeOGavgzIRks"},"source":["7. Créer un pipeline pour normaliser, entraîner et tester le modèle en même temps. Normaliser avec la méthode StandardScaler.\n","Afficher le score sur le jeu de test et expliquez la différence entre les deux\n","méthodes de scaling."]},{"cell_type":"code","execution_count":21,"metadata":{"id":"zMjBDSjXIdxR"},"outputs":[{"name":"stdout","output_type":"stream","text":["Score on standardized test data: 0.5263157894736842\n"]}],"source":["from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","\n","pipe = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=3))\n","\n","pipe.fit(trainX, trainY)\n","score_pipe = pipe.score(testX, testY)\n","print(f\"Score on standardized test data: {score_pipe}\")\n"]},{"cell_type":"markdown","metadata":{"id":"a77fx4nIJatP"},"source":["8. Afin de découvrir les meilleurs hyper-paramètres de votre modèle, utilisez la stratégie GridSearchCV. Faire varier les nombres de voisins entre 1 et 10, et utiliser  les distances euclidean et cosine. Quels sont les meilleurs paramètres? Sauvegarder le meilleur modèle."]},{"cell_type":"code","execution_count":22,"metadata":{"id":"fNGPE4UtKczR"},"outputs":[{"data":{"text/plain":["({'metric': 'cosine', 'n_neighbors': 2}, 0.9608333333333334)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","from sklearn.model_selection import GridSearchCV\n","\n","g = GridSearchCV(KNeighborsClassifier(), {'n_neighbors': np.arange(1, 10), 'metric': ['euclidean',  'cosine']}, cv=5)\n","g.fit(trainX, trainY)\n","g.best_params_, g.best_score_\n"]},{"cell_type":"markdown","metadata":{"id":"FTg8vtrdUYhl"},"source":["9. Montrer les erreurs plus fréquentes de votre modèle à l'aide d'une matrice de confusion."]},{"cell_type":"code","execution_count":23,"metadata":{"id":"PwjC5CF8UVfo"},"outputs":[{"name":"stdout","output_type":"stream","text":["Score : 1.0\n","[[13  0]\n"," [ 0  6]]\n"]}],"source":["from sklearn.metrics import confusion_matrix\n","\n","print('Score :', g.score(testX, testY))\n","print(confusion_matrix(testY, g.predict(testX)))\n"]},{"cell_type":"markdown","metadata":{"id":"muN7hTzvc4GK"},"source":["10. Discuter l'amélioration de modèle KNN, quelle conclusion tireriez-vous de ces expériences?"]},{"cell_type":"markdown","metadata":{},"source":["Les résultats sont bons cependant la taille de l'échantillon testé est vraiment petite il faudrait donc tester sur un plus grand échantillon."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}
