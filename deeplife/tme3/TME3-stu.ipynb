{"cells":[{"cell_type":"markdown","metadata":{"id":"jZ4D84xglI83"},"source":["Nous allons entraîner un classifieur pour distinguer deux familles de protéines : \tABC transporter (PF00005) et \tSH2 domain (PF00017).\n"]},{"cell_type":"markdown","metadata":{"id":"4IQtP0WFl55E"},"source":["1. Charger le fichier trainSeed.csv dans un data frame, la\n","première colonne contient les séquences et la deuxième leur classe PF00017 et PF00005.\n","Puis séparer les séquences et les classes en créant deux objets\n","`Xseqs` et `Y`. Xseqs contient les séquences en acid amine, `Y` l'identifiant Pfam. Dans `Y` nous pouvons remplacer PF00017 par 0 et PF00005 par 1."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"PueUL6RSmvsw"},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"5z1kkab0pJZ1"},"outputs":[],"source":["df = pd.read_csv('trainSeed.csv')\n","# print(df)\n","\n","Xseqs = df['Sequence'].values\n","Y = (df['family'].values == 'PF00005').astype(int)"]},{"cell_type":"markdown","metadata":{"id":"SiGUJzOSm3We"},"source":["2. Nous allons utiliser la bibliothèque [protlearn](https://protlearn.readthedocs.io/en/latest/feature_extraction.html) pour extraire des features qui décrivent nos séquences protéiques. Utiliser la méthode ngram (n=2) pour extraire les fréquences de répétition de dinucléotides pour chaque sequence de `Xseqs`."]},{"cell_type":"code","execution_count":22,"metadata":{"id":"Z3l2f5IroLpP"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting protlearn\n","  Downloading protlearn-0.0.3-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.4/106.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (from protlearn) (1.26.0)\n","Requirement already satisfied: pandas in /opt/homebrew/lib/python3.11/site-packages (from protlearn) (2.0.1)\n","Collecting scikit-learn (from protlearn)\n","  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/75/95/1917ac1ac6de32a087734833e7ecd5631f102cc35020daa2bee8558eca89/scikit_learn-1.4.0-1-cp311-cp311-macosx_12_0_arm64.whl.metadata\n","  Downloading scikit_learn-1.4.0-1-cp311-cp311-macosx_12_0_arm64.whl.metadata (11 kB)\n","Collecting xgboost (from protlearn)\n","  Obtaining dependency information for xgboost from https://files.pythonhosted.org/packages/03/e6/4aef6799badc2693548559bad5b56d56cfe89eada337c815fdfe92175250/xgboost-2.0.3-py3-none-macosx_12_0_arm64.whl.metadata\n","  Downloading xgboost-2.0.3-py3-none-macosx_12_0_arm64.whl.metadata (2.0 kB)\n","Collecting mlxtend (from protlearn)\n","  Obtaining dependency information for mlxtend from https://files.pythonhosted.org/packages/1c/07/512f6a780239ad6ce06ce2aa7b4067583f5ddcfc7703a964a082c706a070/mlxtend-0.23.1-py3-none-any.whl.metadata\n","  Downloading mlxtend-0.23.1-py3-none-any.whl.metadata (7.3 kB)\n","Collecting biopython (from protlearn)\n","  Downloading biopython-1.83.tar.gz (19.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: scipy>=1.2.1 in /opt/homebrew/lib/python3.11/site-packages (from mlxtend->protlearn) (1.11.1)\n","Requirement already satisfied: matplotlib>=3.0.0 in /opt/homebrew/lib/python3.11/site-packages (from mlxtend->protlearn) (3.7.1)\n","Collecting joblib>=0.13.2 (from mlxtend->protlearn)\n","  Obtaining dependency information for joblib>=0.13.2 from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n","  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/lib/python3.11/site-packages (from pandas->protlearn) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas->protlearn) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas->protlearn) (2023.3)\n","Collecting threadpoolctl>=2.0.0 (from scikit-learn->protlearn)\n","  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n","  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend->protlearn) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend->protlearn) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend->protlearn) (4.39.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend->protlearn) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend->protlearn) (23.0)\n","Requirement already satisfied: pillow>=6.2.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend->protlearn) (9.5.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend->protlearn) (3.1.0)\n","Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->protlearn) (1.16.0)\n","Downloading mlxtend-0.23.1-py3-none-any.whl (1.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading scikit_learn-1.4.0-1-cp311-cp311-macosx_12_0_arm64.whl (10.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading xgboost-2.0.3-py3-none-macosx_12_0_arm64.whl (1.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n","Building wheels for collected packages: biopython\n","  Building wheel for biopython (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for biopython: filename=biopython-1.83-cp311-cp311-macosx_13_0_arm64.whl size=2669978 sha256=0090f91259f59bea38a94ce66c945d9051e2a6131a77897b44ac21b217b89428\n","  Stored in directory: /Users/simon/Library/Caches/pip/wheels/56/8c/a5/3dc17a356cfece2215e77575bd8dc89700689f59854bbd7f93\n","Successfully built biopython\n","Installing collected packages: threadpoolctl, joblib, biopython, xgboost, scikit-learn, mlxtend, protlearn\n","Successfully installed biopython-1.83 joblib-1.3.2 mlxtend-0.23.1 protlearn-0.0.3 scikit-learn-1.4.0 threadpoolctl-3.2.0 xgboost-2.0.3\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install protlearn"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"ESRPZ35n195l"},"outputs":[],"source":["from protlearn.features import ngram\n","\n","X, _ = ngram(list(Xseqs), n=2)"]},{"cell_type":"markdown","metadata":{"id":"sXAhR1acSIhA"},"source":["3. Pour entraîner un modèle ML avec [sklearn](https://scikit-learn.org/stable/index.html) nous avons besoin de deux objets ndArray: `X` (de dimensions (NxM) qui comporte les `M` features de chaque protéine) et `y` (de dimension (Nx1) qui contient leurs classes), où N est le nombre total de samples (protéines) dans le dataset. Créer ces deux objets à partir des données chargées précédemment."]},{"cell_type":"code","execution_count":40,"metadata":{"id":"mf4ICX_LsYeN"},"outputs":[{"name":"stdout","output_type":"stream","text":["X.shape=(95, 400) Y.shape=(95,)\n"]}],"source":["# X.shape = (95, 400); y.shape = (95,)\n","\n","print(f'{X.shape=} {Y.shape=}')"]},{"cell_type":"markdown","metadata":{"id":"ZBMdhXd8suHN"},"source":["4. Créer un modèle ML du type KNN (k=3), et juste pour avoir un aperçu de sa performance calculer son score sur les données d'entrainement X."]},{"cell_type":"code","execution_count":41,"metadata":{"id":"Ocd0tKXel3tB"},"outputs":[{"data":{"text/plain":["0.8210526315789474"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","c = KNeighborsClassifier(n_neighbors=3)\n","c.fit(X, Y)\n","c.score(X, Y)\n","\n","#score sur tout = 0.8210526315789474"]},{"cell_type":"markdown","metadata":{"id":"1VgvHosGtLco"},"source":["5. Diviser les données en deux parties, une pour l'entraînement et une pour le test. Utiliser `random_state=5` et `test_size=0.2`.\n","Entraîner le modèle K-NN (k= 3) sur les données d'entraînement et mesurer sa performance sur les données de test. Comparer les scores obtenu sur les donneées de test et sur le données de training.\n"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"5wWuXKHMtTBu"},"outputs":[{"data":{"text/plain":["(0.7894736842105263, 0.42105263157894735)"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.model_selection import train_test_split\n","\n","trainX, testX, trainY, testY = train_test_split(X, Y, random_state=5, test_size=0.2)\n","\n","c = KNeighborsClassifier(n_neighbors=3)\n","c.fit(trainX, trainY)\n","c.score(trainX, trainY), c.score(testX, testY)\n","\n","#score sur training = 0.7894736842105263\n","#score sur test = 0.42105263157894735"]},{"cell_type":"markdown","metadata":{"id":"kinDgT-awkau"},"source":["6. Une étape importante avant d'entraîner les modèles ML, est la normalisation des données. Normaliser les données en utilisant la méthode minmax puis recalculer le score sur les données de test ? Discutez vos résultats.\n"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"fQiyELcXxX6e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Score on normalized test data: 0.47368421052631576\n"]}],"source":["from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","trainX_scaled = scaler.fit_transform(trainX)\n","testX_scaled = scaler.transform(testX)\n","\n","c = KNeighborsClassifier(n_neighbors=3)\n","c.fit(trainX_scaled, trainY)\n","score_normalized = c.score(testX_scaled, testY)\n","print(f\"Score on normalized test data: {score_normalized}\")\n","\n","#score sur test normalisé = 0.47368421052631576"]},{"cell_type":"markdown","metadata":{"id":"MeOGavgzIRks"},"source":["7. Créer un pipeline pour normaliser, entraîner et tester le modèle en même temps. Normaliser avec la méthode StandardScaler.\n","Afficher le score sur le jeu de test et expliquez la différence entre les deux\n","méthodes de scaling."]},{"cell_type":"code","execution_count":49,"metadata":{"id":"zMjBDSjXIdxR"},"outputs":[{"name":"stdout","output_type":"stream","text":["Score on standardized test data: 0.5263157894736842\n"]}],"source":["from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","\n","pipe = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=3))\n","\n","pipe.fit(trainX, trainY)\n","score_pipe = pipe.score(testX, testY)\n","print(f\"Score on standardized test data: {score_pipe}\")\n"]},{"cell_type":"markdown","metadata":{"id":"a77fx4nIJatP"},"source":["8. Afin de découvrir les meilleurs hyper-paramètres de votre modèle, utilisez la stratégie GridSearchCV. Faire varier les nombres de voisins entre 1 et 10, et utiliser  les distances euclidean et cosine. Quels sont les meilleurs paramètres? Sauvegarder le meilleur modèle."]},{"cell_type":"code","execution_count":56,"metadata":{"id":"fNGPE4UtKczR"},"outputs":[{"data":{"text/plain":["({'metric': 'cosine', 'n_neighbors': 2}, 0.9608333333333334)"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","from sklearn.model_selection import GridSearchCV\n","\n","g = GridSearchCV(KNeighborsClassifier(), {'n_neighbors': np.arange(1, 10), 'metric': ['euclidean',  'cosine']}, cv=5)\n","g.fit(trainX, trainY)\n","g.best_params_, g.best_score_"]},{"cell_type":"markdown","metadata":{"id":"FTg8vtrdUYhl"},"source":["9. Montrer les erreurs plus fréquentes de votre modèle à l'aide d'une matrice de confusion."]},{"cell_type":"code","execution_count":57,"metadata":{"id":"PwjC5CF8UVfo"},"outputs":[{"data":{"text/plain":["(1.0,\n"," array([[13,  0],\n","        [ 0,  6]]))"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.metrics import confusion_matrix\n","\n","g.score(testX, testY), confusion_matrix(testY, g.predict(testX))"]},{"cell_type":"markdown","metadata":{"id":"muN7hTzvc4GK"},"source":["10. Discuter l'amélioration de modèle KNN, quelle conclusion tireriez-vous de ces expériences?"]},{"cell_type":"markdown","metadata":{},"source":["Les résultats sont bons cependant la taille de l'échantillon testé est vraiment petite il faudrait donc tester sur un plus grand échantillon."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":0}
