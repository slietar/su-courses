{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5297,"status":"ok","timestamp":1711629722588,"user":{"displayName":"Anna von Bachmann","userId":"01675554630686370026"},"user_tz":-60},"id":"ZtFHtTBH8Hgr","outputId":"ee16634f-7f73-4091-d6ff-6ada7c5d5f6d"},"outputs":[],"source":["#### Setup ####\n","# install and import required packages\n","!pip install scanpy\n","import torch; torch.manual_seed(100)\n","import torch.nn as nn\n","import torch.utils\n","import torch.distributions\n","import torchvision\n","from torchvision import datasets, transforms\n","import math\n","import numpy as np\n","np.random.seed(100)\n","import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n","import scanpy as sc\n","from collections import OrderedDict\n","from collections import Counter\n","\n","# select the right device, depending on whether your Colab runs on GPU or CPU\n","### IMPORTANT: we recommend to change your runtime to GPU, otherwise the training takes much longer\n","device = 'mps'\n","print(device)\n"]},{"cell_type":"markdown","metadata":{"id":"6L4KM-KybhSF"},"source":["## Interpretable variational autoencoders for the analysis of scRNA-Seq data\n","### Objective\n","\n","In this practical session, you will learn how variational autoencoders (VAEs) can be modified to be biologically interpretable and how these models can be used to analyze **biological processes**. <br>\n","We will first build a \"standard\" VAE, which provides a low dimensional representation of the data set with a clear clustering into conditions and cell types, but whose features are **not directly interpretable**. <br>\n","\n","Then, we will modify this VAE, so that its latent variables can be directly interpreted as **biological processes**. Therefore, we will follow the same principle that is applied in **VEGA**, proposed by [Seninge *et al* (2021)](https://www.nature.com/articles/s41467-021-26017-0) (more about this later). We will use this model to compare pathway activities between cell types and treatment conditions. <br>\n","\n","### Data set\n","For the analysis, we will use a data set that contains peripheral blood mononuclear cells (PBMCs) from systemic lupus patients, treated with Interferon beta or untreated (control). The data set is already preprocessed and is stored as an **AnnData** object. You can read more about this data format [here](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/getting-started.html).<br>\n","\n","An AnnData object contains the gene expression data in its `.X` attribute, stored as a sparse matrix. Annotations for the observations (cells) are stored in the `.obs` attribute, and annotations for the variables (genes) in the `.var` attribute. We can select specific features of the `.obs` or `.var` attribute using squared brackets, e.g. `PBMC_train.obs[\"cell_type\"]` :"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4605,"status":"ok","timestamp":1711629727186,"user":{"displayName":"Anna von Bachmann","userId":"01675554630686370026"},"user_tz":-60},"id":"9Fs0gLaK8t25","outputId":"7e6c526f-1379-438e-9d32-b8f9466cf6a9"},"outputs":[],"source":["# download the data\n","!curl -L 'https://docs.google.com/uc?export=download&id=1zHJKoU8QcQB4cLR-oICO2YY4Nu-QaZHG' -o PBMC_train.h5ad\n","# load data as anndata object\n","PBMC_train = sc.read_h5ad(\"PBMC_train.h5ad\")\n"]},{"cell_type":"markdown","metadata":{"id":"g4dT3AMzcPAp"},"source":["Let's take a closer look at the data:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":295,"status":"ok","timestamp":1711629727477,"user":{"displayName":"Anna von Bachmann","userId":"01675554630686370026"},"user_tz":-60},"id":"mXW3k4tIkrIZ","outputId":"a0a7948f-8de5-40b7-ec0c-eb95e2c29d6f"},"outputs":[],"source":["print(PBMC_train) #the data is stored as an anndata object\n","print(Counter(PBMC_train.obs[\"cell_type\"])) #summary of cell types\n","print(Counter(PBMC_train.obs[\"condition\"])) #summary of conditions\n"]},{"cell_type":"markdown","metadata":{"id":"vzVxCjV2hJO8"},"source":["## Standard VAE\n","\n","We will first build a \"standard\" VAE. The code for this is not explained in detail, since this should be already familiar from previous sessions. <br>\n","\n","We define the `Encoder` as a two-layer, non-linear and fully connected neural network. The latent space is sampled from a multivariate normal distribution. We further use dropout layers in the encoder/latent space:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FtBSMERo2S0u"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, latent_dims, input_dims, dropout, z_dropout): #dropout, z_dropout define the dropout rates of the encoder/latent space\n","        super(Encoder, self).__init__()\n","        self.encoder = nn.Sequential(nn.Linear(input_dims, 800),\n","                                     nn.ReLU(),\n","                                     nn.Dropout(p = dropout),\n","                                     nn.Linear(800, 800),\n","                                     nn.ReLU(),\n","                                     nn.Dropout(p = dropout))  #two layer, fully connected encoder with dropout\n","\n","\n","        self.mu = nn.Sequential(nn.Linear(800, latent_dims),\n","                                nn.Dropout(p = z_dropout))\n","\n","        self.sigma = nn.Sequential(nn.Linear(800, latent_dims),\n","                                   nn.Dropout(p = z_dropout))\n","\n","        self.N = torch.distributions.Normal(0, 1)\n","        self.N.loc = self.N.loc.to(device)\n","        self.N.scale = self.N.scale.to(device)\n","        self.kl = 0\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        mu =  self.mu(x)\n","        sigma = torch.exp(self.mu(x)) # exp for numeric stability\n","        z = mu + sigma*self.N.sample(mu.shape)\n","        self.kl = (0.5*sigma**2 + 0.5*mu**2 - torch.log(sigma) - 1/2).sum() #calculation of kullback-leibler divergence\n","\n","        return z\n"]},{"cell_type":"markdown","metadata":{"id":"ZzfPCwrIiOxV"},"source":["We further define the `Decoder` as two-layer, non linear and fully connected neural network:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E07kSyjt5cUf"},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, latent_dims, input_dims, dropout):\n","        super(Decoder, self).__init__()\n","        self.decoder = nn.Sequential(nn.Linear(latent_dims, 800),\n","                                     nn.ReLU(),\n","                                     nn.Dropout(p = dropout),\n","                                     nn.Linear(800, input_dims)\n","                                     )\n","\n","    def forward(self, z):\n","        z = self.decoder(z)\n","        return z\n"]},{"cell_type":"markdown","metadata":{"id":"nIA7L8O70MWM"},"source":["The class `VariationalAutoencoder` combines the Encoder and Decoder:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QCoqYSVu0MWN"},"outputs":[],"source":["class VariationalAutoencoder(nn.Module):\n","    def __init__(self, latent_dims, input_dims,dropout = 0.3, z_dropout=0.3):\n","        super(VariationalAutoencoder, self).__init__()\n","        self.encoder = Encoder(latent_dims, input_dims, dropout, z_dropout)\n","        self.decoder = Decoder(latent_dims, input_dims, dropout)\n","\n","    def forward(self, x):\n","        z = self.encoder(x)\n","        return self.decoder(z)\n"]},{"cell_type":"markdown","metadata":{"id":"6r8UBS8H0MWN"},"source":["In order to train the model, we use the following training function, which returns the trained model and a list of the losses after each epoch. Beta defines the weight of the KLD."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dMrAWFLj0MWN"},"outputs":[],"source":["def train(vae, data, epochs=50, beta = 0.001, learning_rate = 0.0001):\n","    opt = torch.optim.Adam(vae.parameters(), lr = learning_rate) # ADAM optimizer\n","    losses = []\n","    klds = []\n","    mses = []\n","    vae.train() #train mode (then, dropout layers are considered)\n","\n","    for epoch in range(epochs):\n","        loss_e = 0\n","        kld_e = 0\n","        mse_e = 0\n","\n","        for x in data:\n","            x = x.to(device)\n","            opt.zero_grad()\n","            x_hat = vae(x)\n","            mse = ((x - x_hat)**2).sum()\n","            kld = beta* vae.encoder.kl\n","            loss = mse +  kld # loss calculation\n","            loss.backward()\n","            opt.step()\n","            loss_e += loss.to('cpu').detach().numpy()\n","            kld_e += kld.to('cpu').detach().numpy()\n","            mse_e += mse.to('cpu').detach().numpy()\n","\n","        losses.append(loss_e/(len(data)*128))\n","        klds.append(kld_e/(len(data)*128))\n","        mses.append(mse_e/(len(data)*128))\n","\n","        print(\"epoch: \", epoch, \" loss: \", loss_e/(len(data)*128))\n","\n","    return vae, losses, klds, mses\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ipnkjDmX_qSL"},"outputs":[],"source":["PBMC_trainX = torch.utils.data.DataLoader(PBMC_train.X.A, batch_size=128) #set up the training data in the right format\n","latent_dims = 50 #choose the number of latent variables\n"]},{"cell_type":"markdown","metadata":{"id":"WkFXY0QBkTRs"},"source":["We can now initialize our VAE and use the PBMC data to train the model:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65786,"status":"ok","timestamp":1711629795412,"user":{"displayName":"Anna von Bachmann","userId":"01675554630686370026"},"user_tz":-60},"id":"nXinXHx40MWN","outputId":"8fa075b3-d789-4211-f2d1-b35e06168c09"},"outputs":[],"source":["vae = VariationalAutoencoder(latent_dims = latent_dims, input_dims = PBMC_train.shape[1]).to(device)\n","vae, losses, klds, mses = train(vae, PBMC_trainX, beta = 1) # takes about 1 min on GPU\n"]},{"cell_type":"markdown","metadata":{"id":"ldnfLVuM0MWN"},"source":["We can plot the loss curve and see that it converges well:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":860},"executionInfo":{"elapsed":608,"status":"ok","timestamp":1711629796009,"user":{"displayName":"Anna von Bachmann","userId":"01675554630686370026"},"user_tz":-60},"id":"bl0vqNG_FlSK","outputId":"cdad9d51-5b19-4ef0-f715-a9e41047a86e"},"outputs":[],"source":["plt.plot(losses)\n"]},{"cell_type":"markdown","metadata":{"id":"JuzZJKDAYxUB"},"source":["We can further look at the MSE and the KLD:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":860},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1711629796009,"user":{"displayName":"Anna von Bachmann","userId":"01675554630686370026"},"user_tz":-60},"id":"Retul8fOYw9z","outputId":"3d7f701b-ae02-47ee-cacf-44b378455cd7"},"outputs":[],"source":["plt.plot(mses, label = \"MSE\")\n","plt.legend()\n","plt.gca().twinx().plot(klds, color='r', label = \"KLD\")\n","plt.legend()\n"]},{"cell_type":"markdown","metadata":{"id":"tiLC5hYNcSl_"},"source":["We can project the data to the latent space, and store this in the anndata object:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vswu3hZ8cKoa"},"outputs":[],"source":["def to_latent(vae, adata):\n","        latent = []\n","        data = torch.tensor(adata.X.A).to(device)\n","        vae.eval() # we need to set the model to evaluation mode, so that the dropout is no longer considered\n","        z = vae.encoder(data)\n","        latent += [z.to(\"cpu\")]\n","        return torch.cat(latent).detach().numpy()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gvL75XqjczEi"},"outputs":[],"source":["PBMC_train.obsm[\"latent_embedding\"] = to_latent(vae, PBMC_train)\n"]},{"cell_type":"markdown","metadata":{"id":"LtCWggV_is46"},"source":["We can further visualize the embedding of the cells in the latent space using UMAP:  "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(PBMC_train.obsm[\"latent_embedding\"].shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2877,"status":"ok","timestamp":1711630077524,"user":{"displayName":"Anna von Bachmann","userId":"01675554630686370026"},"user_tz":-60},"id":"E5rhYljygvdr","outputId":"4f9aa10a-f9b0-4958-ef27-f338ad7a7026"},"outputs":[],"source":["sc.pp.neighbors(PBMC_train, use_rep='latent_embedding', n_neighbors=15) # use_rep specifies that the calculation is based on the latent embedding\n","sc.tl.umap(PBMC_train, random_state=1) #set random state to ensure reproducibility\n","sc.pl.umap(PBMC_train, color=[\"cell_type\", \"condition\"], size=10, ncols = 1)\n"]},{"cell_type":"markdown","metadata":{"id":"bC9aWVLPkyO9"},"source":["We can see a clear separation into cell types and conditions. However, the latent variables are **not directly interpretable**, i.e. we don't know the biological importance of these features.<br>\n","\n","> Repeat this analysis with a smaller latent space (reduce the number of `latent_dims`) → Can you see an effect? If so, can you explain it?\n","\n","It is faster to compute with a lower number of latent dimensions but there is less information and thus clustering is less efficient.\n","\n","> How does the proportions of the MSE and KLD in the loss function affect the cell's embedding in the latent space? To assess this, try larger values for `beta`. Can you explain the observed changes in the latent embedding?\n","\n","With a higher `beta`, the KLD is more important when computing the loss which results in the latent space being smoother and the data more difficult to cluster.\n","\n","## Biologically Interpretable VAEs\n","To achieve a **direct interpretability** of the model's features, we can modify the architecture of the VAE. Our aim is, that every latent variable represents a **biological pathway**. We follow the same principle that is applied in **VEGA** ([Seninge *et al* (2021)](https://www.nature.com/articles/s41467-021-26017-0)).<br>\n","\n","We want to provide the interpretability through the model's **decoder**, and therefore apply the following modifications:\n","\n","1. **one-layer** decoder: every latent variable is directly connected to the output variables.\n","2. **linear** decoder: we do not use any activation function (sigmoid, ReLU,...) in the decoder.\n","3. **positive** decoder: we restrict the decoder weights to positive values by setting all negative weights to zero. This allows direct interpretability of the activities of the latent variables.\n","4. **sparse** decoder: we use prior-defined gene modules to define the decoder connections. Every latent variable is associated with a specific biological term (pathway) and is only connected to output genes that are related to this pathway."]},{"cell_type":"markdown","metadata":{"id":"GG1enDZ5krIe"},"source":["We first need to provide the gene modules that define the model's decoder connections. We use a .gmt file that contains genesets of pathways."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":346,"status":"ok","timestamp":1711629815279,"user":{"displayName":"Anna von Bachmann","userId":"01675554630686370026"},"user_tz":-60},"id":"YZ_bUlfZ3TU7","outputId":"6eb23d86-6b69-4155-c597-f5e59f39d580"},"outputs":[],"source":["# download the .gmt file\n","\n","!curl -L -o reactomes.gmt https://raw.githubusercontent.com/LucasESBS/vega-reproducibility/main/data/reactomes.gmt\n"]},{"cell_type":"markdown","metadata":{"id":"dapo0ZwqkrIe"},"source":["Lets first have a look at this file: <br>\n","The first column specifies the gene modulating variable (GMV), in this case the pathway. The second column includes information of the data base, and the following columns contain the genes of the geneset:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1711629815279,"user":{"displayName":"Anna von Bachmann","userId":"01675554630686370026"},"user_tz":-60},"id":"WmCD3kj43odm","outputId":"5e03cf83-f0bc-4377-b962-edeab344bd4c"},"outputs":[],"source":["with open('reactomes.gmt') as gmt_file: #print first lines of the gmt file\n","    gmt_head = gmt_file.readlines()[0:10]\n","    for row in gmt_head:\n","      print(row)\n"]},{"cell_type":"markdown","metadata":{"id":"B6mWBaaskrIf"},"source":["Based on this .gmt file, we first write a function to create a **mask $M$**, that we will use later to define the decoder connections. <br>\n","\n","The rows of the mask $M$ correspond to genes (of the data set), the columns to pathways (of the .gmt file). If the gene $i$ is annotated in the gene set of the pathway $j$, the corresponding entry of the matrix $M(i,j)$ contains the value 1, otherwise the value 0. <br>\n","\n","We can further add **fully connected nodes** to the latent space (with the parameter `add_nodes`), that are connected to all output variables. This allows better data reconstruction and compensates for connections, that are missing in our prior defined gene sets (these are likely incomplete). These fully connected nodes are also included in the mask (all values are ones)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wv9NW-tmoWxY"},"outputs":[],"source":["####### In the following sections, we used and adapted code from https://github.com/LucasESBS/vega ######\n","\n","def create_mask(adata, gmt_path:str=None, add_nodes:int=1, sep = \"\\t\"):\n","    \"\"\"\n","    Initialize mask M for GMVs from a .gmt file\n","    Args:\n","        adata (Anndata): Scanpy single-cell object, we will store the computed mask and the names of the biological processes there\n","        gmt_path (str): path to .gmt file\n","        add_nodes (int): Additional latent nodes for capturing additional variance\n","    Return:\n","        adata (Anndata): Scanpy single-cell object that now stores the computed mask and the names of biological processes (in the .uns[\"_vega\"] attribute)\n","        mask (array): mask M that specifies whether a gene is included in the gene set of a pathway (value one) or not (value zero)\n","    \"\"\"\n","\n","    gmv_dict = OrderedDict()\n","    with open(gmt_path) as f:\n","        for line in f.readlines():\n","            line = line.strip()\n","            spli = line.split(sep)\n","            gmv_dict[spli[0]] = spli[2:]\n","\n","    feature_list = adata.var.index.tolist()\n","\n","\n","    # Create mask\n","    mask = np.zeros((len(feature_list), len(gmv_dict)))\n","    for j, k in enumerate(gmv_dict.keys()):\n","        for i in range(mask.shape[0]):\n","            if feature_list[i] in gmv_dict[k]:\n","                mask[i,j] = 1.\n","    # Add unannotated nodes\n","    vec = np.ones((mask.shape[0], add_nodes))\n","    mask = np.hstack((mask, vec))\n","\n","    adata.uns['_vega'] = dict() #create attribute \"_vega\" to store the mask and pathway information\n","    adata.uns['_vega']['mask'] = mask\n","    adata.uns['_vega']['gmv_names'] = list(gmv_dict.keys()) + ['UNANNOTATED_'+str(k) for k in range(add_nodes)]\n","\n","    return adata, mask\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"76PRg_n51Rc0"},"outputs":[],"source":["# we can now create the mask from the .gmt file and our data set\n","PBMC_train, mask = create_mask(PBMC_train, gmt_path= \"reactomes.gmt\", add_nodes=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1711629819001,"user":{"displayName":"Anna von Bachmann","userId":"01675554630686370026"},"user_tz":-60},"id":"_cOZ86e65ACs","outputId":"8675d3ca-fe2c-4d39-8aba-5c132d6fedf0"},"outputs":[],"source":["# Let's take a look at the mask:\n","print(mask.shape)\n","print(mask)\n","# we can see that the mask stores zeroes and ones\n","# the last column contains only ones, since this column represents the fully connected node (connected to all output genes)\n"]},{"cell_type":"markdown","metadata":{"id":"uRLANOr7krIg"},"source":["Since we want to achieve the interpretability through the model's **decoder**, we can just modify this part of the architecture while using the same encoder as before:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vr4zoHCFn4Mh"},"outputs":[],"source":["# define VEGA's decoder\n","\n","class DecoderVEGA(nn.Module):\n","  \"\"\"\n","  Define VEGA's decoder (sparse, one-layer, linear, positive)\n","  \"\"\"\n","  def __init__(self,\n","               mask):\n","        super(DecoderVEGA, self).__init__()\n","\n","        self.sparse_layer = nn.Sequential(SparseLayer(mask)) # we define the architecture of the decoder below with the class \"SparseLayer\"\n","\n","  def forward(self, x):\n","    z = self.sparse_layer(x.to(device))\n","    return(z)\n","\n","  def positive_weights(self):\n","      \"\"\"\n","      constrain the decoder to positive weights (set negative weigths to zero)\n","      \"\"\"\n","      w = self.sparse_layer[0].weight\n","      w.data = w.data.clamp(0)\n","      return w\n","\n","\n","# define a class SparseLayer, that specifies the decoder architecture (sparse connections based on the mask)\n","class SparseLayer(nn.Module):\n","  def __init__(self, mask):\n","        \"\"\"\n","        Extended torch.nn module which mask connection\n","        \"\"\"\n","        super(SparseLayer, self).__init__()\n","\n","        self.mask = nn.Parameter(torch.tensor(mask, dtype=torch.float).t(), requires_grad=False)\n","        self.weight = nn.Parameter(torch.Tensor(mask.shape[1], mask.shape[0]))\n","        self.bias = nn.Parameter(torch.Tensor(mask.shape[1]))\n","        self.reset_parameters()\n","\n","        # mask weight\n","        self.weight.data = self.weight.data * self.mask\n","\n","  def reset_parameters(self):\n","        stdv = 1. / math.sqrt(self.weight.size(1))\n","        self.weight.data.uniform_(-stdv, stdv)\n","        self.bias.data.uniform_(-stdv, stdv)\n","\n","  def forward(self, input):\n","        # See the autograd section for explanation of what happens here\n","        return SparseLayerFunction.apply(input, self.weight, self.bias, self.mask)\n","\n","\n","######### You don't need to understand this part of the code in detail #########\n","class SparseLayerFunction(torch.autograd.Function):\n","    \"\"\"\n","    We define our own autograd function which masks it's weights by 'mask'.\n","    For more details, see https://pytorch.org/docs/stable/notes/extending.html\n","    \"\"\"\n","\n","    # Note that both forward and backward are @staticmethods\n","    @staticmethod\n","    def forward(ctx, input, weight, bias, mask):\n","\n","        weight = weight * mask # change weight to 0 where mask == 0\n","        #calculate the output\n","        output = input.mm(weight.t())\n","        output += bias.unsqueeze(0).expand_as(output) # Add bias to all values in output\n","        ctx.save_for_backward(input, weight, bias, mask)\n","        return output\n","\n","    @staticmethod\n","    def backward(ctx, grad_output): # define the gradient formula\n","        input, weight, bias, mask = ctx.saved_tensors\n","        grad_input = grad_weight = grad_bias = grad_mask = None\n","\n","        # These needs_input_grad checks are optional and only to improve efficiency\n","        if ctx.needs_input_grad[0]:\n","            grad_input = grad_output.mm(weight)\n","        if ctx.needs_input_grad[1]:\n","            grad_weight = grad_output.t().mm(input)\n","            # change grad_weight to 0 where mask == 0\n","            grad_weight = grad_weight * mask\n","        if ctx.needs_input_grad[2]:\n","            grad_bias = grad_output.sum(0).squeeze(0)\n","\n","        return grad_input, grad_weight, grad_bias, grad_mask\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w_K6yFgs8rRO"},"outputs":[],"source":["class VEGA(nn.Module):\n","    def __init__(self, latent_dims, input_dims, mask, dropout = 0.3, z_dropout = 0.3):\n","        super(VEGA, self).__init__()\n","        self.encoder = Encoder(latent_dims, input_dims, dropout, z_dropout) # we use the same encoder as before (two-layer, fully connected, non-linear)\n","        self.decoder = DecoderVEGA(mask)\n","\n","    def forward(self, x):\n","        z = self.encoder(x)\n","        return self.decoder(z)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"puReN5l2JC9t"},"outputs":[],"source":["#training loop\n","def trainVEGA(vae, data, epochs=100, beta = 0.0001, learning_rate = 0.001):\n","    opt = torch.optim.Adam(vae.parameters(), lr = learning_rate, weight_decay = 5e-4)\n","    vae.train() #train mode\n","    losses = []\n","    klds = []\n","    mses = []\n","\n","    for epoch in range(epochs):\n","        loss_e = 0\n","        kld_e = 0\n","        mse_e = 0\n","\n","        for x in data:\n","            x = x.to(device)\n","            opt.zero_grad()\n","            x_hat = vae(x)\n","            mse = ((x - x_hat)**2).sum()\n","            kld = beta* vae.encoder.kl\n","            loss = mse +  kld # loss calculation\n","            loss.backward()\n","            opt.step()\n","            loss_e += loss.to('cpu').detach().numpy()\n","            kld_e += kld.to('cpu').detach().numpy()\n","            mse_e += mse.to('cpu').detach().numpy()\n","            vae.decoder.positive_weights() # we restrict the decoder for positive weights\n","\n","        losses.append(loss_e/(len(data)*128))\n","        klds.append(kld_e/(len(data)*128))\n","        mses.append(mse_e/(len(data)*128))\n","\n","        print(\"epoch: \", epoch, \" loss: \", loss_e/(len(data)*128))\n","\n","    return vae, losses, klds, mses\n"]},{"cell_type":"markdown","metadata":{"id":"-bOUK1mgo4A9"},"source":["We initialize the VEGA model, based on the mask that we constructed above:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":108636,"status":"ok","timestamp":1711629927631,"user":{"displayName":"Anna von Bachmann","userId":"01675554630686370026"},"user_tz":-60},"id":"3wk38R6k5nBV","outputId":"3abacb47-1366-4c86-d42e-15f317f6da1e"},"outputs":[],"source":["vega = VEGA(latent_dims= mask.shape[1], input_dims = mask.shape[0], mask = mask.T, z_dropout = 0.5, dropout = 0.3).to(device)\n","# model training\n","vega, vega_losses, vega_klds, vega_mses = trainVEGA(vega, PBMC_trainX,epochs = 100, beta = 0.0001) #takes about 2 mins on GPU\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":860},"executionInfo":{"elapsed":691,"status":"ok","timestamp":1711629928311,"user":{"displayName":"Anna von Bachmann","userId":"01675554630686370026"},"user_tz":-60},"id":"Nq7kZZsv5vak","outputId":"21a9edf2-bc5b-4a7a-ec1c-a37ed4ff5053"},"outputs":[],"source":["# plot the loss curve\n","plt.plot(vega_losses)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":860},"executionInfo":{"elapsed":365,"status":"ok","timestamp":1711629928665,"user":{"displayName":"Anna von Bachmann","userId":"01675554630686370026"},"user_tz":-60},"id":"pVWBtQA7aqOc","outputId":"fe6f64f6-63f4-42ca-efce-7dc4c07f6e0b"},"outputs":[],"source":["# plot mse and kld\n","plt.plot(vega_mses, label = \"MSE\")\n","plt.gca().twinx().plot(vega_klds, label = \"KLD\")\n","plt.legend()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1711629928666,"user":{"displayName":"Anna von Bachmann","userId":"01675554630686370026"},"user_tz":-60},"id":"DA1Xm6LjCEHe","outputId":"1dddd02f-fde8-4e4f-97a6-a99bfc504b26"},"outputs":[],"source":["# we can see that all decoder weights are positive:\n","print(torch.sum(vega.state_dict()[\"decoder.sparse_layer.0.weight\"]<0)) # zero negative weights\n"]},{"cell_type":"markdown","metadata":{"id":"Dn14hfU4pNcn"},"source":["Again, we can have a look at the embedding of the cells in the latent space, colored by condition and cell type:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":18540,"status":"ok","timestamp":1711631304802,"user":{"displayName":"Anna von Bachmann","userId":"01675554630686370026"},"user_tz":-60},"id":"bunPATWUJbZ5","outputId":"71535dfd-c88f-4353-fdaf-663046a5d3a7"},"outputs":[],"source":["PBMC_train.obsm[\"latent_embedding\"] = to_latent(vega, PBMC_train) # project the cells to the model's latent space\n","\n","# UMAP based on the latent embedding\n","sc.pp.neighbors(PBMC_train, use_rep='latent_embedding', n_neighbors=15)\n","sc.tl.umap(PBMC_train, random_state=1) #set random state to ensure reproducibility\n","sc.pl.umap(PBMC_train, color=[\"cell_type\", \"condition\"], size=10, ncols = 1)\n"]},{"cell_type":"markdown","metadata":{"id":"yr71nEQKp0Ie"},"source":["Since the latent variables now each correspond to a specific pathway, we can further color the cells according to pathway activities:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":876},"executionInfo":{"elapsed":1118,"status":"ok","timestamp":1711631360242,"user":{"displayName":"Anna von Bachmann","userId":"01675554630686370026"},"user_tz":-60},"id":"IscMceywpu84","outputId":"aecaed1e-6eb9-455e-d074-0ff5e43d776e"},"outputs":[],"source":["pathway_of_interest = \"REACTOME_INTERFERON_ALPHA_BETA_SIGNALING\"\n","\n","pathways = PBMC_train.uns[\"_vega\"][\"gmv_names\"] # the names of the GMVs are stored here\n","pw_activities = PBMC_train.obsm[\"latent_embedding\"] # pathway activities (we stored them here when projecting the data to the latent space (see above))\n","\n","#for visualization with the scanpy package, we need to provide the annotation (based on which cells should be colored) in the .obs attribute\n","PBMC_train.obs[pathway_of_interest] =  PBMC_train.obsm[\"latent_embedding\"][:,pathways.index(pathway_of_interest)]\n","sc.pl.umap(PBMC_train, color=[pathway_of_interest], size=10, ncols = 1)\n"]},{"cell_type":"markdown","metadata":{"id":"cUPJe9xoqX0D"},"source":["As expected, the `\"REACTOME_INTERFERON_ALPHA_BETA_SIGNALING\"` pathway is more active in IFNb stimulated cells!\n","\n","> Color the cells according to `'REACTOME_ANTIVIRAL_MECHANISM_BY_IFN_STIMULATED_GENES'`, `'REACTOME_DOPAMINE_NEUROTRANSMITTER_RELEASE_CYCLE'` and `'REACTOME_DOWNSTREAM_SIGNALING_EVENTS_OF_B_CELL_RECEPTOR_BCR'`. Can you observe the expected results? If not, what could be the reason for this?"]},{"cell_type":"markdown","metadata":{"id":"SGb6PP2P7klG"},"source":["We can further determine important genes for specific pathways by looking at the **decoder weights**. <br>\n","We therefore define a function to plot the ranked weights:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h5pYQ7us7fwu"},"outputs":[],"source":["def plot_ranked_gene_weights(model: VEGA, adata,\n","                        gmv,\n","                        n_genes: int = 10):\n","    \"\"\"\n","    Plot gene members of input GMVs according to their magnitude.\n","    \"\"\"\n","    w = vega.state_dict()[\"decoder.sparse_layer.0.weight\"].to(\"cpu\")\n","    gmv_names = list(adata.uns['_vega']['gmv_names'])\n","    gene_names = adata.var.index.tolist()\n","\n","\n","    # Get values\n","    i = gmv_names.index(gmv)\n","    w_i = w[:,i].detach().numpy()\n","    sort_idx = np.argsort(w_i)[::-1]\n","    sort_w = w_i[sort_idx][:n_genes]\n","    genes = np.array(gene_names)[sort_idx][:n_genes]\n","\n","    # Set plot params\n","    ymin = np.min(sort_w)\n","    ymax = np.max(sort_w)\n","    ymax += 0.3*(ymax - ymin)\n","\n","    # Plot\n","    for ig, gene_name in enumerate(genes):\n","        plt.text(\n","            ig,\n","            sort_w[ig],\n","            gene_name,\n","            rotation='vertical',\n","            verticalalignment='bottom',\n","            horizontalalignment='center',\n","            color=\"black\"\n","        )\n","    plt.title(gmv)\n","    plt.ylim(ymin, ymax)\n","    plt.xlim(-0.9, n_genes - 0.1)\n","    plt.xlabel('Ranking')\n","    plt.ylabel('Weight magnitude')\n","    plt.xticks(np.arange(0, n_genes, step=1), labels = np.arange(1, n_genes+1, step=1))\n","\n","    plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"CETpPaRZn9TT"},"source":["For instance, we can identify ISGs (Interferon stimulated genes) and IFITs (Interferon Induced Proteins With Tetratricopeptide Repeat) for the Interferon alpha/beta signaling pathway:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":924},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1711629946235,"user":{"displayName":"Anna von Bachmann","userId":"01675554630686370026"},"user_tz":-60},"id":"fCYC-NNM7jIW","outputId":"5af6caac-c241-41be-86b2-41a457a22bc6"},"outputs":[],"source":["plot_ranked_gene_weights(vega, gmv= \"REACTOME_INTERFERON_ALPHA_BETA_SIGNALING\", adata = PBMC_train, n_genes = 20)\n"]},{"cell_type":"markdown","metadata":{"id":"jdLCTD-ekrIk"},"source":["## Exercises\n","1. Adding fully connected nodes improves the data reconstruction and can compensate for missing links in our prior defined gene modules. However, what potential drawbacks might arise from adding too many of these nodes?\n","\n","2. As you have seen above, we added a dropout layer in the model's latent space. What could be the advantage of this?\n","\n","3. We provide a set of validation data below (`PBMC_valid`). <br>\n","Can you add this validation data to the training loop, and check whether our model is **overfitted**? For this, plot both loss curves (training and validation), and explain how we could identify potential overfitting based on these curves.<br>\n","Can you explain why the loss of the validation set is smaller than the loss of the training set?\n","<br> *Hint:* First, you need to set up the data set in the right format with the `torch.utils.data.DataLoader()` function. Then, iterate over this data within the training loop. Make sure to set the model to evaluation mode (with `vae.eval()`) and to not update the parameters, since this is only for validation!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3342,"status":"ok","timestamp":1711629949558,"user":{"displayName":"Anna von Bachmann","userId":"01675554630686370026"},"user_tz":-60},"id":"-P5cRIzqvp7M","outputId":"fbd396d5-c7b6-46c6-9c69-0858619a3167"},"outputs":[],"source":["# download the data\n","!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1rJKZYIG7rv7BQbDD9RElYOgHcxxzjcYj' -O PBMC_valid.h5ad\n","# load data as anndata object\n","PBMC_valid = sc.read_h5ad( \"PBMC_valid.h5ad\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GQl_oew2bDIr"},"outputs":[],"source":["###### provide your solution for exercise 3 here ######\n","\n","### Here you should set up the data\n","PBMC_validX =\n","\n","### training loop\n","def trainVEGA_with_valid(vae, data, val_data, epochs=100, beta = 0.0001, learning_rate = 0.001):\n","    opt = torch.optim.Adam(vae.parameters(), lr = learning_rate, weight_decay = 5e-4)\n","    train_losses = []\n","    valid_losses = []\n","    for epoch in range(epochs):\n","        train_loss_e = 0\n","        valid_loss_e = 0\n","        vae.train() #train mode\n","\n","        for x in data:\n","            x = x.to(device) # GPU\n","            opt.zero_grad()\n","            x_hat = vae(x)\n","            loss = ((x - x_hat)**2).sum() + beta* vae.encoder.kl\n","            loss.backward()\n","            opt.step()\n","            train_loss_e += loss.to('cpu').detach().numpy()\n","            vae.decoder.positive_weights() # we restrict the decoder to positive weights\n","        train_losses.append(train_loss_e/(len(data)*128))\n","\n","        #### Here you should add the validation loop\n","\n","        print(\"epoch: \", epoch, \" train_loss: \", train_loss_e/(len(data)*128))\n","        #### print also the validation loss after each epoch!\n","\n","    return vae, train_losses, valid_losses\n","\n","\n","# model initialization and training\n","vega = VEGA(latent_dims= mask.shape[1], input_dims = mask.shape[0], mask = mask.T, dropout = 0.3, z_dropout = 0.3).to(device)\n","vega, train_losses, valid_losses = trainVEGA_with_valid(vega, PBMC_trainX, PBMC_validX, epochs = 50, beta = 0.0001)\n","\n","\n","### plot the loss curves:\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}
