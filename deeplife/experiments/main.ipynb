{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "example_dataset = torchvision.datasets.FashionMNIST(\n",
    "  download=True,\n",
    "  root=Path('data/fashion'),\n",
    "  train=True,\n",
    "  # transform=v2.PILToTensor()\n",
    "  transform=v2.Compose([\n",
    "    v2.PILToTensor(),\n",
    "    v2.RandomRotation(90.0),\n",
    "  ])\n",
    ")\n",
    "\n",
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "\n",
    "for index, ax in enumerate(axes.flat):\n",
    "  image, label = example_dataset[index]\n",
    "  ax.imshow(image.view(28, 28), cmap='gray')\n",
    "  ax.set_title(labels_map[label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset: Dataset[float] = torchvision.datasets.FashionMNIST(\n",
    "  download=True,\n",
    "  root=Path('data/fashion'),\n",
    "  train=True,\n",
    "  transform=v2.Compose([\n",
    "    v2.PILToTensor(),\n",
    "    v2.ToDtype(torch.float)\n",
    "  ]),\n",
    "  target_transform=torchvision.transforms.Lambda(lambda y: torch.zeros(10).scatter_(0, torch.tensor(y), value=1))\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "  download=True,\n",
    "  root=Path('data/fashion'),\n",
    "  train=False,\n",
    "  transform=v2.Compose([\n",
    "    v2.PILToTensor(),\n",
    "    v2.ToDtype(torch.float)\n",
    "  ]),\n",
    "  # target_transform=torchvision.transforms.Lambda(lambda y: torch.zeros(10).scatter_(0, torch.tensor(y), value=1))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "device = 'mps'\n",
    "\n",
    "class Model(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.stack = nn.Sequential(\n",
    "      # nn.Flatten(),\n",
    "      # nn.Linear(28 * 28, 64),\n",
    "      nn.Conv2d(1, 2, kernel_size=3),\n",
    "      nn.MaxPool2d(kernel_size=2),\n",
    "      # nn.Flatten(2, 3),\n",
    "      nn.Flatten(),\n",
    "      nn.ReLU(),\n",
    "      # nn.Linear(26 * 26, 512),\n",
    "      # nn.ReLU(),\n",
    "      nn.Linear(2 * 13 * 13, 10),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    logits = self.stack(x)\n",
    "    return logits\n",
    "\n",
    "model = Model().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "with torch.no_grad():\n",
    "  print(model.forward(next(iter(train_dataloader))[0].to(device)).shape)\n",
    "  print(model.forward(train_dataset[0][0].unsqueeze(0).to(device)).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop():\n",
    "  size = len(train_dataloader.dataset)\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  for batch_index, (x, y) in enumerate(train_dataloader):\n",
    "    batch_size = x.size(0)\n",
    "\n",
    "    pred = model(x.to(device))\n",
    "    loss = loss_fn(pred, y.to(device))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if batch_index % 100 == 0:\n",
    "      loss, current = loss.item(), batch_index * batch_size + len(X)\n",
    "      print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop():\n",
    "  model.eval()\n",
    "\n",
    "  size = len(test_dataloader.dataset)\n",
    "  batch_count = len(test_dataloader)\n",
    "  test_loss = 0\n",
    "  correct_count = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for x, y in test_dataloader:\n",
    "      yd = y.to(device)\n",
    "      pred = model(x.to(device))\n",
    "      test_loss += loss_fn(pred, yd).item()\n",
    "      correct_count += (pred.argmax(1) == yd).type(torch.float).sum().item()\n",
    "\n",
    "  test_loss /= batch_count\n",
    "  correct_count /= size\n",
    "\n",
    "  print(f\"Test Error:\\n  Accuracy: {(100*correct_count):>0.1f}%\\n  Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "for t in range(10):\n",
    "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "  train_loop()\n",
    "  test_loop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder\n",
    "\n",
    "class Model(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    latent_dims = 8\n",
    "\n",
    "    self.encoder = nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(28 * 28, 512),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(512, latent_dims),\n",
    "    )\n",
    "\n",
    "    self.decoder = nn.Sequential(\n",
    "      nn.Linear(latent_dims, 512),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(512, 28 * 28),\n",
    "      # nn.ReLU(),\n",
    "      # nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "\n",
    "    return self.decoder(self.encoder(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def train_loop():\n",
    "  model.train()\n",
    "\n",
    "  for batch_index, (x, _) in enumerate(train_dataloader):\n",
    "    dx = x.to(device) / 0xff\n",
    "    decoded = model(dx)\n",
    "    loss = loss_fn(dx.flatten(1), decoded)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if batch_index % 100 == 0:\n",
    "      print(f\"  loss: {loss.item():>7f}\")\n",
    "\n",
    "for t in range(1):\n",
    "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "  train_loop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2)\n",
    "\n",
    "with torch.no_grad():\n",
    "  raw_image = train_dataset[7][0]\n",
    "  image = raw_image.unsqueeze(0).to(device)\n",
    "  decoded = model(image).cpu()\n",
    "\n",
    "  axs[0].imshow(raw_image[0, ...], cmap='gray')\n",
    "  axs[1].imshow(decoded[0, :].view(28, 28), cmap='gray')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
